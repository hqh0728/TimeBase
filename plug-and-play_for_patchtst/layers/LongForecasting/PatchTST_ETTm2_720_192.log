Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='720_192', model='PatchTST', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=192, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, use_gpu=True, gpu=6, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:6
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
MACs: 266434560.0
Params: 2611648.0
266.43M MACs
>>>>>>>start training : 720_192_PatchTST_ETTm2_ftM_sl720_ll48_pl192_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5003428
	speed: 0.1111s/iter; left time: 865.9551s
	iters: 200, epoch: 1 | loss: 0.4343322
	speed: 0.1039s/iter; left time: 799.0916s
Epoch: 1 cost time: 28.22829246520996
Epoch: 1, Steps: 263 | Train Loss: 0.4132094 Vali Loss: 0.1758011 Test Loss: 0.2439092
Validation loss decreased (inf --> 0.175801).  Saving model ...
Updating learning rate to 5.636591374463056e-06
	iters: 100, epoch: 2 | loss: 0.3192673
	speed: 0.3028s/iter; left time: 2279.2358s
	iters: 200, epoch: 2 | loss: 0.3023817
	speed: 0.1110s/iter; left time: 824.5723s
Epoch: 2 cost time: 30.019461631774902
Epoch: 2, Steps: 263 | Train Loss: 0.3337744 Vali Loss: 0.1616488 Test Loss: 0.2253328
Validation loss decreased (0.175801 --> 0.161649).  Saving model ...
Updating learning rate to 1.0434764192561907e-05
	iters: 100, epoch: 3 | loss: 0.2526746
	speed: 0.3372s/iter; left time: 2449.8316s
	iters: 200, epoch: 3 | loss: 0.3418107
	speed: 0.1071s/iter; left time: 767.7066s
Epoch: 3 cost time: 28.90803623199463
Epoch: 3, Steps: 263 | Train Loss: 0.3079691 Vali Loss: 0.1595865 Test Loss: 0.2176420
Validation loss decreased (0.161649 --> 0.159587).  Saving model ...
Updating learning rate to 1.8067324777326426e-05
	iters: 100, epoch: 4 | loss: 0.2692629
	speed: 0.3222s/iter; left time: 2256.1191s
	iters: 200, epoch: 4 | loss: 0.2423169
	speed: 0.1050s/iter; left time: 724.4656s
Epoch: 4 cost time: 29.565136909484863
Epoch: 4, Steps: 263 | Train Loss: 0.2962467 Vali Loss: 0.1589418 Test Loss: 0.2160863
Validation loss decreased (0.159587 --> 0.158942).  Saving model ...
Updating learning rate to 2.8013798844669414e-05
	iters: 100, epoch: 5 | loss: 0.3465455
	speed: 0.3292s/iter; left time: 2218.5979s
	iters: 200, epoch: 5 | loss: 0.2360900
	speed: 0.1151s/iter; left time: 764.1916s
Epoch: 5 cost time: 29.803179502487183
Epoch: 5, Steps: 263 | Train Loss: 0.2885317 Vali Loss: 0.1619613 Test Loss: 0.2226868
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.959592332521864e-05
	iters: 100, epoch: 6 | loss: 0.3090225
	speed: 0.3760s/iter; left time: 2435.0282s
	iters: 200, epoch: 6 | loss: 0.2569355
	speed: 0.1120s/iter; left time: 713.9830s
Epoch: 6 cost time: 30.997398376464844
Epoch: 6, Steps: 263 | Train Loss: 0.2768929 Vali Loss: 0.1608417 Test Loss: 0.2195716
EarlyStopping counter: 2 out of 5
Updating learning rate to 5.2023898009689775e-05
	iters: 100, epoch: 7 | loss: 0.1906720
	speed: 0.3662s/iter; left time: 2275.2956s
	iters: 200, epoch: 7 | loss: 0.2146867
	speed: 0.1145s/iter; left time: 700.1725s
Epoch: 7 cost time: 30.332453966140747
Epoch: 7, Steps: 263 | Train Loss: 0.2648344 Vali Loss: 0.1647519 Test Loss: 0.2306883
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.4450243057639e-05
	iters: 100, epoch: 8 | loss: 0.2498337
	speed: 0.3718s/iter; left time: 2211.9358s
	iters: 200, epoch: 8 | loss: 0.2258597
	speed: 0.1096s/iter; left time: 641.3059s
Epoch: 8 cost time: 30.1897394657135
Epoch: 8, Steps: 263 | Train Loss: 0.2466845 Vali Loss: 0.1667186 Test Loss: 0.2420629
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.602758975566739e-05
	iters: 100, epoch: 9 | loss: 0.2922057
	speed: 0.3127s/iter; left time: 1778.0606s
	iters: 200, epoch: 9 | loss: 0.3246057
	speed: 0.1088s/iter; left time: 607.9405s
Epoch: 9 cost time: 29.129918098449707
Epoch: 9, Steps: 263 | Train Loss: 0.2334873 Vali Loss: 0.1671420 Test Loss: 0.2511162
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : 720_192_PatchTST_ETTm2_ftM_sl720_ll48_pl192_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.21665990352630615, mae:0.2942354083061218, rse:0.3767769932746887
