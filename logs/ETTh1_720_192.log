Args in experiment:
Namespace(is_training=1, model_id='ETTh1_720_192', model='LightTimeBaseTST', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=192, period_len=24, basis_num=6, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.16, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=256, patience=5, learning_rate=0.4, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:1
242
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 38304.0
Params: 242.0
38304.0 MACs
>>>>>>>start training : ETTh1_720_192_LightTimeBaseTST_ETTh1_ftM_sl720_pl192_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Max Memory (MB): 26.0341796875
Epoch: 1 cost time: 1.0172536373138428
Epoch: 1, Steps: 31 | Train Loss: 0.5250273 Vali Loss: 1.1351261 Test Loss: 0.4306258
Validation loss decreased (inf --> 1.135126).  Saving model ...
Updating learning rate to 0.4
Max Memory (MB): 26.0341796875
Epoch: 2 cost time: 0.9704630374908447
Epoch: 2, Steps: 31 | Train Loss: 0.5558098 Vali Loss: 1.1881052 Test Loss: 0.4963949
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.4
Max Memory (MB): 26.0341796875
Epoch: 3 cost time: 1.0534858703613281
Epoch: 3, Steps: 31 | Train Loss: 0.4697892 Vali Loss: 1.1579870 Test Loss: 0.4909813
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.4
Max Memory (MB): 26.0341796875
Epoch: 4 cost time: 1.103529691696167
Epoch: 4, Steps: 31 | Train Loss: 0.6902193 Vali Loss: 1.5197476 Test Loss: 0.5574898
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.32000000000000006
Max Memory (MB): 26.0341796875
Epoch: 5 cost time: 1.4901936054229736
Epoch: 5, Steps: 31 | Train Loss: 0.5778856 Vali Loss: 0.9739382 Test Loss: 0.3959071
Validation loss decreased (1.135126 --> 0.973938).  Saving model ...
Updating learning rate to 0.25600000000000006
Max Memory (MB): 26.0341796875
Epoch: 6 cost time: 1.4425787925720215
Epoch: 6, Steps: 31 | Train Loss: 0.4357559 Vali Loss: 1.0034351 Test Loss: 0.4186611
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.20480000000000007
Max Memory (MB): 26.0341796875
Epoch: 7 cost time: 1.0308024883270264
Epoch: 7, Steps: 31 | Train Loss: 0.4214058 Vali Loss: 1.0172719 Test Loss: 0.4292774
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.16384000000000004
Max Memory (MB): 26.0341796875
Epoch: 8 cost time: 1.049325942993164
Epoch: 8, Steps: 31 | Train Loss: 0.4142940 Vali Loss: 1.0387108 Test Loss: 0.4528288
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.13107200000000005
Max Memory (MB): 26.0341796875
Epoch: 9 cost time: 0.9826862812042236
Epoch: 9, Steps: 31 | Train Loss: 0.4098036 Vali Loss: 1.0337532 Test Loss: 0.4244789
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.10485760000000005
Max Memory (MB): 26.0341796875
Epoch: 10 cost time: 1.3782641887664795
Epoch: 10, Steps: 31 | Train Loss: 0.4048520 Vali Loss: 1.0283223 Test Loss: 0.4295678
EarlyStopping counter: 5 out of 5
Early stopping
Final Max Memory (MB): 26.0341796875
>>>>>>>testing : ETTh1_720_192_LightTimeBaseTST_ETTh1_ftM_sl720_pl192_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3877432346343994, mae:0.41012272238731384, rse:0.5913293957710266
